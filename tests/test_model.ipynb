{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ['https_proxy'] = 'http://172.17.0.1:1081'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/axolotl/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 14:17:50,024] [INFO] [axolotl.utils.config.models.input.check_eval_packing:991] [PID:1479193] [RANK:0] explicitly setting `eval_sample_packing` to match `sample_packing`\u001b[39m\n",
      "[2024-11-11 14:17:50,030] [INFO] [axolotl.normalize_config:183] [PID:1479193] [RANK:0] GPU memory usage baseline: 0.000GB (+1.184GB misc)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlpspec': {'emb_dim': 4096,\n",
       "  'inner_dim': 3072,\n",
       "  'n_candidates': 5,\n",
       "  'n_predict': 4,\n",
       "  'top_k_tokens_per_head': [4, 3, 2, 2],\n",
       "  'vocab_size': 128256},\n",
       " 'medusa_logging': False,\n",
       " 'medusa_scheduler': 'constant',\n",
       " 'medusa_only_heads': False,\n",
       " 'medusa_num_unfreeze_layers': 0,\n",
       " 'medusa_distillation_regularization': 0,\n",
       " 'medusa_self_distillation': False,\n",
       " 'type_of_model': 'LlamaForCausalLM',\n",
       " 'lisa_layers_attribute': 'model.layers',\n",
       " 'wandb_project': 'mlpspec_test',\n",
       " 'gradient_accumulation_steps': 4,\n",
       " 'micro_batch_size': 2,\n",
       " 'train_on_inputs': False,\n",
       " 'group_by_length': False,\n",
       " 'learning_rate': 0.0005,\n",
       " 'weight_decay': 0.0,\n",
       " 'optimizer': <OptimizerNames.ADAMW_BNB: 'adamw_bnb_8bit'>,\n",
       " 'lr_scheduler': <SchedulerType.COSINE: 'cosine'>,\n",
       " 'num_epochs': 4,\n",
       " 'load_in_8bit': False,\n",
       " 'load_in_4bit': False,\n",
       " 'lora_dropout': 0.0,\n",
       " 'qlora_sharded_model_loading': False,\n",
       " 'loraplus_lr_embedding': 1e-06,\n",
       " 'output_dir': './outputs/llama3-8b-instruct',\n",
       " 'base_model': '/models/Meta-Llama-3-8B-Instruct',\n",
       " 'base_model_config': '/models/Meta-Llama-3-8B-Instruct',\n",
       " 'tokenizer_type': 'LlamaTokenizer',\n",
       " 'strict': False,\n",
       " 'datasets': [{'path': '/models/datasets/ShareGPT/',\n",
       "   'type': 'sharegpt',\n",
       "   'data_files': 'ShareGPT_V4.3_unfiltered_cleaned_split.json',\n",
       "   'trust_remote_code': False}],\n",
       " 'shuffle_merged_datasets': True,\n",
       " 'dataset_processes': 128,\n",
       " 'ddp_find_unused_parameters': True,\n",
       " 'bf16': True,\n",
       " 'fp16': False,\n",
       " 'tf32': False,\n",
       " 'gradient_checkpointing': True,\n",
       " 'sequence_len': 4096,\n",
       " 'max_prompt_len': 512,\n",
       " 'sample_packing': True,\n",
       " 'sample_packing_group_size': 100000,\n",
       " 'sample_packing_bin_size': 200,\n",
       " 'eval_sample_packing': True,\n",
       " 'pad_to_sequence_len': True,\n",
       " 'pretrain_multipack_buffer_size': 10000,\n",
       " 'pretrain_multipack_attn': True,\n",
       " 'flash_attention': True,\n",
       " 'val_set_size': 0.01,\n",
       " 'special_tokens': {'bos_token': '<|begin_of_text|>',\n",
       "  'eos_token': '<|end_of_text|>'},\n",
       " 'warmup_steps': 40,\n",
       " 'eval_steps': 40,\n",
       " 'save_total_limit': 1,\n",
       " 'logging_steps': 1,\n",
       " 'load_best_model_at_end': False,\n",
       " 'save_only_model': False,\n",
       " 'axolotl_config_path': '../examples/mlpspec/llama3-8b-instruct.yaml',\n",
       " 'is_llama_derived_model': True,\n",
       " 'capabilities': {'bf16': True,\n",
       "  'fp8': False,\n",
       "  'n_gpu': 1,\n",
       "  'n_node': 1,\n",
       "  'compute_capability': 'sm_89'},\n",
       " 'batch_size': 8,\n",
       " 'eval_batch_size': 2,\n",
       " 'world_size': 1,\n",
       " 'local_rank': 0,\n",
       " 'eval_table_size': 0,\n",
       " 'eval_max_new_tokens': 128,\n",
       " 'eval_causal_lm_metrics': ['sacrebleu', 'comet', 'ter', 'chrf'],\n",
       " 'device': 'cuda:0',\n",
       " 'device_map': 'auto',\n",
       " 'ddp': False,\n",
       " 'torch_dtype': torch.bfloat16,\n",
       " 'model_config_type': 'llama',\n",
       " 'tokenizer_config': '/models/Meta-Llama-3-8B-Instruct',\n",
       " 'is_falcon_derived_model': False,\n",
       " 'is_mistral_derived_model': False,\n",
       " 'is_qwen_derived_model': None,\n",
       " 'gradient_checkpointing_kwargs': {'use_reentrant': True},\n",
       " 'use_wandb': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from axolotl.cli import load_cfg\n",
    "\n",
    "\n",
    "cfg = load_cfg('../examples/mlpspec/llama3-8b-instruct.yaml')\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axolotl.prompt_strategies.sharegpt import register_llama3_template\n",
    "\n",
    "\n",
    "register_llama3_template(cfg.default_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from axolotl.utils.models import load_model, load_tokenizer\n",
    "\n",
    "\n",
    "#tokenizer = load_tokenizer(cfg)\n",
    "#tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='/models/Meta-Llama-3-8B-Instruct', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128004: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128005: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128008: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128010: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128011: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128012: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128013: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128014: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128015: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128016: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128017: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128018: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128019: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128020: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128021: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128022: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128023: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128024: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128025: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128026: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128027: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128028: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128029: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128030: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128031: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128032: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128033: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128034: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128035: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128036: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128037: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128038: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128039: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128040: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128041: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128042: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128043: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128044: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128045: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128046: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128047: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128048: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128049: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128050: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128051: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128052: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128053: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128054: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128055: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128056: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128057: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128058: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128059: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128060: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128061: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128062: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128063: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128064: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128065: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128066: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128067: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128068: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128069: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128070: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128071: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128072: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128073: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128074: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128075: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128076: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128077: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128078: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128079: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128080: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128081: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128082: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128083: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128084: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128085: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128086: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128087: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128088: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128089: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128090: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128091: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128092: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128093: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128094: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128095: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128096: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128097: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128098: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128099: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128100: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128101: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128102: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128103: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128104: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128105: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128106: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128107: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128108: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128109: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128110: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128111: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128112: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128113: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128114: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128115: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128116: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128117: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128118: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128119: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128120: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128121: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128122: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128123: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128124: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128125: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128126: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128127: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128128: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128129: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128130: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128131: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128132: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128133: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128134: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128135: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128136: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128137: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128138: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128139: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128140: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128141: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128142: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128143: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128144: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128145: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128146: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128147: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128148: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128149: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128150: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128151: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128152: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128153: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128154: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128155: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128156: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128157: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128158: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128159: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128160: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128161: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128162: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128163: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128164: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128165: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128166: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128167: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128168: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128169: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128170: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128171: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128172: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128173: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128174: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128175: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128176: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128177: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128178: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128179: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128180: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128181: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128182: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128183: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128184: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128185: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128186: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128187: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128188: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128189: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128190: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128191: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128192: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128193: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128194: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128195: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128196: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128197: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128198: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128199: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128200: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128201: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128202: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128203: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128204: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128205: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128206: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128207: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128208: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128209: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128210: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128211: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128212: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128213: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128214: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128215: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128216: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128217: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128218: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128219: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128220: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128221: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128222: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128223: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128224: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128225: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128226: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128227: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128228: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128229: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128230: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128231: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128232: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128233: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128234: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128235: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128236: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128237: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128238: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128239: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128240: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128241: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128242: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128243: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128244: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128245: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128246: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128247: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128248: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128249: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128250: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128251: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128252: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128253: AddedToken(\"<|reserved_special_token_248|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128254: AddedToken(\"<|reserved_special_token_249|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128255: AddedToken(\"<|reserved_special_token_250|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.base_model_config, use_fast=False)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 14:17:51,051] [INFO] [accelerate.utils.modeling.get_balanced_memory:1005] [PID:1479193] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:00<00:00, 15.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-11 14:18:52,032] [INFO] [axolotl.load_model:841] [PID:1479193] [RANK:0] GPU memory usage after model load: 14.958GB (+0.126GB cache)\u001b[39m\n",
      "[2024-11-11 14:18:52,055] [INFO] [axolotl.load_model:906] [PID:1479193] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "cfg.mlpspec={'emb_dim': 4096, 'inner_dim': 3072, 'n_candidates': 5, 'n_predict': 4, 'top_k_tokens_per_head': [4, 3, 2, 2], 'vocab_size': 128256}\n",
      "\u001b[33m[2024-11-11 14:19:33,651] [WARNING] [axolotl.load_model:1120] [PID:1479193] [RANK:0] there are no parameters that require gradient updates\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  (mlp_model): MLPSpeculatorPreTrainedModel(\n",
       "    (speculator): MLPSpeculator(\n",
       "      (emb): ModuleList(\n",
       "        (0-3): 4 x Embedding(128256, 3072)\n",
       "      )\n",
       "      (proj): ModuleList(\n",
       "        (0): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "        (1-3): 3 x Linear(in_features=3072, out_features=3072, bias=False)\n",
       "      )\n",
       "      (head): ModuleList(\n",
       "        (0-3): 4 x Linear(in_features=3072, out_features=128256, bias=False)\n",
       "      )\n",
       "      (ln): ModuleList(\n",
       "        (0-3): 4 x LayerNormParameterized()\n",
       "      )\n",
       "      (activation): GELU(approximate='none')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from axolotl.utils.models import load_model\n",
    "\n",
    "\n",
    "model, peft_config = load_model(cfg, tokenizer, inference=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[128000,  15339,     11,   1148]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode('hello, what', return_tensors=\"pt\").to('cuda')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPast(last_hidden_state=tensor([[[ 4.2188, -0.2041, -1.8438,  ..., -2.8594,  1.3594,  0.2891],\n",
       "         [-1.4141, -0.7109, -0.5469,  ..., -0.8203, -1.8672,  1.6484],\n",
       "         [-1.7812, -3.1406,  3.7344,  ..., -1.9062, -1.3750,  2.5312],\n",
       "         [-3.7969, -3.3438,  4.9062,  ...,  1.0312,  1.1406,  3.1406]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), past_key_values=None, hidden_states=(tensor([[[-8.2970e-05,  2.5749e-04, -2.4605e-04,  ..., -3.2425e-04,\n",
       "          -2.1553e-04,  4.7112e-04],\n",
       "         [ 1.3123e-02, -1.8066e-02,  7.7438e-04,  ..., -7.6904e-03,\n",
       "           7.2937e-03,  9.9487e-03],\n",
       "         [-2.5558e-04, -4.1199e-04,  3.6478e-05,  ...,  2.1267e-04,\n",
       "           3.1471e-05,  2.9182e-04],\n",
       "         [ 7.9346e-03, -5.2795e-03,  9.3384e-03,  ...,  4.4556e-03,\n",
       "           6.8359e-03,  6.1951e-03]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0014,  0.0040, -0.0050,  ...,  0.0093, -0.0007,  0.0005],\n",
       "         [ 0.0056, -0.0192,  0.0093,  ..., -0.0019, -0.0098,  0.0044],\n",
       "         [ 0.0014,  0.0069,  0.0121,  ...,  0.0024, -0.0031, -0.0039],\n",
       "         [ 0.0203,  0.0032,  0.0181,  ...,  0.0046,  0.0167,  0.0183]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-4.5654e-02,  9.5703e-02, -5.9570e-02,  ...,  5.5859e-01,\n",
       "           1.5723e-01, -1.4648e-02],\n",
       "         [ 5.0735e-04, -2.0630e-02,  8.2397e-03,  ...,  1.4587e-02,\n",
       "          -2.5391e-02,  7.8125e-03],\n",
       "         [-1.5259e-05,  5.2795e-03,  1.8433e-02,  ...,  1.3672e-02,\n",
       "           1.2268e-02,  1.4648e-02],\n",
       "         [ 2.3682e-02, -1.0254e-02,  2.8564e-02,  ...,  6.9580e-03,\n",
       "           2.2339e-02,  5.0781e-02]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0481,  0.0981, -0.0547,  ...,  0.5664,  0.1650, -0.0210],\n",
       "         [ 0.0127, -0.0173,  0.0081,  ...,  0.0625, -0.0398,  0.0286],\n",
       "         [-0.0064, -0.0271,  0.0320,  ...,  0.0236, -0.0183,  0.0542],\n",
       "         [ 0.0417, -0.0269,  0.0209,  ..., -0.0247,  0.0181,  0.0767]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0327,  0.1045, -0.0381,  ...,  0.6055,  0.1602, -0.0227],\n",
       "         [-0.0153,  0.0223, -0.0145,  ...,  0.0398, -0.0289,  0.0009],\n",
       "         [-0.0114, -0.0024,  0.0271,  ...,  0.0461, -0.0081,  0.0610],\n",
       "         [ 0.0132, -0.0171,  0.0242,  ..., -0.0160,  0.0096,  0.1084]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0469,  0.0972, -0.0308,  ...,  0.5820,  0.1846, -0.0115],\n",
       "         [ 0.0115,  0.0072,  0.0161,  ...,  0.0415, -0.0396, -0.0182],\n",
       "         [ 0.0403,  0.0138,  0.0801,  ...,  0.0256, -0.0087,  0.0571],\n",
       "         [ 0.0542, -0.0239, -0.0010,  ..., -0.0035,  0.0278,  0.0796]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0364,  0.0967, -0.0260,  ...,  0.5664,  0.1953, -0.0054],\n",
       "         [ 0.0092,  0.0542, -0.0342,  ...,  0.0508, -0.0391,  0.0244],\n",
       "         [ 0.0032, -0.0093,  0.0500,  ...,  0.0566,  0.0203,  0.0796],\n",
       "         [ 0.0752, -0.0065, -0.0114,  ..., -0.0014,  0.0146,  0.1221]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0498,  0.1172, -0.0284,  ...,  0.5430,  0.2012, -0.0087],\n",
       "         [ 0.0208,  0.0508, -0.0845,  ...,  0.0903,  0.0151, -0.0132],\n",
       "         [ 0.0264, -0.0581,  0.0483,  ...,  0.1094,  0.0503,  0.0198],\n",
       "         [ 0.0220, -0.0332, -0.0366,  ...,  0.0017,  0.0544,  0.1484]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0347,  0.1562, -0.0566,  ...,  0.4980,  0.2012,  0.0094],\n",
       "         [ 0.0400,  0.0020, -0.0552,  ..., -0.0288, -0.0576, -0.0317],\n",
       "         [ 0.0116, -0.1172,  0.0371,  ...,  0.0398,  0.0603,  0.0114],\n",
       "         [ 0.0167, -0.0532, -0.0060,  ..., -0.0356,  0.0430,  0.1963]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0398,  0.1836, -0.0415,  ...,  0.4512,  0.2109,  0.0150],\n",
       "         [ 0.0231,  0.0874, -0.0146,  ...,  0.0347, -0.0547, -0.0413],\n",
       "         [-0.0240, -0.1089,  0.0569,  ...,  0.0591,  0.0513, -0.0630],\n",
       "         [-0.0190, -0.0654,  0.0140,  ..., -0.0259,  0.0055,  0.0908]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-3.4668e-02,  1.9824e-01, -6.2012e-02,  ...,  4.2383e-01,\n",
       "           2.3242e-01,  3.7842e-02],\n",
       "         [-1.4038e-02,  4.1992e-02, -2.3193e-02,  ...,  5.3711e-02,\n",
       "          -1.1230e-02, -3.7598e-02],\n",
       "         [-1.2817e-02, -7.6172e-02,  1.0059e-01,  ...,  6.9824e-02,\n",
       "           7.4707e-02, -1.0352e-01],\n",
       "         [-3.6621e-04, -1.1621e-01,  5.9082e-02,  ..., -2.2949e-02,\n",
       "           1.0693e-01,  8.7891e-02]]], device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0128,  0.2695, -0.0596,  ...,  0.3418,  0.2490,  0.0444],\n",
       "         [ 0.0074,  0.0115, -0.0098,  ...,  0.0464,  0.0022, -0.0737],\n",
       "         [ 0.0085, -0.1133,  0.1328,  ...,  0.0176,  0.0889, -0.1206],\n",
       "         [ 0.0156, -0.1001,  0.0339,  ..., -0.0591,  0.0752,  0.1318]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0229,  0.2969, -0.0977,  ...,  0.3281,  0.2656,  0.0481],\n",
       "         [-0.0029,  0.0035, -0.0035,  ...,  0.0332,  0.0135, -0.0452],\n",
       "         [ 0.0253, -0.0557,  0.1533,  ...,  0.0037,  0.0593, -0.0879],\n",
       "         [ 0.0073, -0.0664, -0.0144,  ..., -0.0854,  0.0342,  0.1201]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0308,  0.3086, -0.0869,  ...,  0.2812,  0.2490,  0.0415],\n",
       "         [ 0.0142, -0.0260, -0.0059,  ...,  0.0879, -0.0488,  0.0072],\n",
       "         [-0.0227, -0.1504,  0.0967,  ...,  0.0376, -0.0405, -0.0452],\n",
       "         [ 0.0112, -0.0928,  0.0527,  ..., -0.1128,  0.0093,  0.1660]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0225,  0.3008, -0.1226,  ...,  0.2266,  0.2500,  0.0498],\n",
       "         [-0.0591, -0.0576, -0.0376,  ...,  0.0811, -0.0077, -0.0166],\n",
       "         [-0.0820, -0.0889,  0.1172,  ...,  0.0101,  0.0193, -0.0275],\n",
       "         [-0.0354, -0.1279,  0.0566,  ..., -0.1475,  0.0542,  0.1406]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0125,  0.2793, -0.1162,  ...,  0.2314,  0.2734, -0.0144],\n",
       "         [-0.0464, -0.0630, -0.0481,  ...,  0.0112, -0.0874, -0.0352],\n",
       "         [-0.1494, -0.0825,  0.0366,  ..., -0.0227, -0.0060, -0.0864],\n",
       "         [-0.0388, -0.0986,  0.0034,  ..., -0.1309,  0.0742,  0.1543]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0231,  0.1973, -0.0732,  ...,  0.1748,  0.3008, -0.0410],\n",
       "         [-0.0488, -0.0466, -0.1162,  ...,  0.0742, -0.0728, -0.1035],\n",
       "         [-0.1089, -0.0183, -0.0066,  ...,  0.0854, -0.1738, -0.0300],\n",
       "         [ 0.0071, -0.0339,  0.0508,  ..., -0.1133,  0.0063,  0.2344]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0330,  0.1992, -0.0659,  ...,  0.1689,  0.3242, -0.0557],\n",
       "         [ 0.0259, -0.0200, -0.0928,  ..., -0.0181, -0.1270, -0.1167],\n",
       "         [-0.1123,  0.2021,  0.1167,  ..., -0.0371, -0.2773, -0.0654],\n",
       "         [ 0.0801, -0.0762,  0.0825,  ..., -0.1064, -0.0518,  0.2734]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0544,  0.1719, -0.0618,  ...,  0.1641,  0.3848, -0.0669],\n",
       "         [ 0.0405, -0.0615, -0.0801,  ..., -0.0315, -0.1040, -0.0928],\n",
       "         [-0.2617,  0.0254,  0.0708,  ..., -0.0278, -0.3203, -0.0305],\n",
       "         [ 0.0225, -0.1807,  0.1934,  ..., -0.0464, -0.0427,  0.3809]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0703,  0.1650, -0.0454,  ...,  0.1709,  0.3516, -0.0835],\n",
       "         [ 0.0366, -0.0176, -0.0308,  ..., -0.0120, -0.0435, -0.0156],\n",
       "         [-0.2656,  0.0262,  0.0991,  ..., -0.0238, -0.1914,  0.0574],\n",
       "         [-0.0859, -0.1943,  0.1533,  ..., -0.1045,  0.0820,  0.5000]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0752,  0.1670, -0.0273,  ...,  0.1719,  0.3477, -0.0447],\n",
       "         [ 0.0723,  0.0250,  0.0198,  ..., -0.0635, -0.0243,  0.0918],\n",
       "         [-0.2637, -0.0544,  0.0938,  ..., -0.1504, -0.0757,  0.1562],\n",
       "         [-0.0610, -0.2324,  0.1445,  ..., -0.1162,  0.1973,  0.4902]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0757,  0.1533, -0.0315,  ...,  0.1738,  0.3164, -0.0298],\n",
       "         [-0.0425, -0.0148,  0.0403,  ..., -0.1152, -0.0264,  0.0308],\n",
       "         [-0.3652, -0.0854,  0.1895,  ..., -0.1641, -0.1465,  0.1455],\n",
       "         [-0.1982, -0.2334,  0.1602,  ..., -0.0762,  0.2422,  0.5703]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0674,  0.1494, -0.0179,  ...,  0.1904,  0.3184, -0.0090],\n",
       "         [-0.1328,  0.0649,  0.0281,  ..., -0.0457, -0.0986,  0.0928],\n",
       "         [-0.4160, -0.0742,  0.1206,  ..., -0.1426, -0.2324,  0.2031],\n",
       "         [-0.2949, -0.2578,  0.2773,  ..., -0.1221,  0.0713,  0.6875]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0435,  0.1416, -0.0198,  ...,  0.1982,  0.3223, -0.0135],\n",
       "         [-0.1123, -0.0234,  0.0850,  ..., -0.0435,  0.0415,  0.1001],\n",
       "         [-0.3398, -0.1245,  0.1465,  ..., -0.2285, -0.1914,  0.2168],\n",
       "         [-0.3184, -0.3613,  0.2441,  ..., -0.1680,  0.0415,  0.7188]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0452,  0.1299, -0.0547,  ...,  0.1953,  0.2871, -0.0339],\n",
       "         [-0.1621, -0.0447,  0.0972,  ..., -0.0439, -0.0840,  0.0283],\n",
       "         [-0.3125, -0.1904,  0.1904,  ..., -0.2520, -0.2451,  0.2617],\n",
       "         [-0.3809, -0.4023,  0.1562,  ..., -0.1699, -0.0771,  0.6484]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0311,  0.1289, -0.0491,  ...,  0.1924,  0.2773, -0.0332],\n",
       "         [-0.1152,  0.1396,  0.1748,  ..., -0.0115, -0.1240,  0.1719],\n",
       "         [-0.3066, -0.1289,  0.2266,  ..., -0.2236, -0.2266,  0.2988],\n",
       "         [-0.3926, -0.2559,  0.1895,  ..., -0.1836, -0.0933,  0.8945]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0315,  0.1074, -0.0781,  ...,  0.2119,  0.2637, -0.0300],\n",
       "         [-0.2734,  0.1152,  0.1699,  ...,  0.1123, -0.1680,  0.2891],\n",
       "         [-0.4609, -0.1855,  0.2314,  ..., -0.1992, -0.2949,  0.3281],\n",
       "         [-0.5938, -0.2480,  0.1377,  ..., -0.2168,  0.0342,  0.9062]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0256,  0.1191, -0.0845,  ...,  0.1943,  0.2812, -0.0334],\n",
       "         [-0.2930, -0.0010,  0.2930,  ...,  0.0342, -0.2480,  0.3574],\n",
       "         [-0.5273, -0.2930,  0.4062,  ..., -0.1641, -0.4141,  0.3750],\n",
       "         [-0.6953, -0.2227,  0.1953,  ..., -0.1631,  0.0859,  0.9414]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[-0.0099,  0.1240, -0.0447,  ...,  0.2021,  0.3262, -0.0298],\n",
       "         [-0.2715, -0.1152,  0.3516,  ...,  0.0864, -0.3359,  0.3457],\n",
       "         [-0.4902, -0.2988,  0.5234,  ..., -0.2988, -0.6250,  0.4316],\n",
       "         [-0.8008, -0.3340,  0.1035,  ..., -0.0977, -0.0518,  1.0391]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.0225,  0.1367, -0.0471,  ...,  0.1768,  0.3242, -0.0176],\n",
       "         [-0.4590, -0.2617,  0.3477,  ...,  0.0674, -0.3984,  0.3926],\n",
       "         [-0.6172, -0.3711,  0.7305,  ..., -0.2334, -0.6562,  0.6445],\n",
       "         [-0.9219, -0.5195,  0.2773,  ..., -0.0308,  0.0322,  0.9766]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.1270,  0.1523, -0.0400,  ...,  0.1377,  0.1680, -0.0840],\n",
       "         [-0.3984, -0.2773,  0.4004,  ...,  0.1426, -0.4844,  0.3945],\n",
       "         [-0.5977, -0.6641,  0.8086,  ..., -0.2578, -0.7031,  0.6758],\n",
       "         [-1.0078, -0.5195,  0.3516,  ...,  0.0452, -0.0869,  0.9297]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 0.1309,  0.2363, -0.0083,  ...,  0.1748, -0.0762, -0.1650],\n",
       "         [-0.4961, -0.1748,  0.2412,  ..., -0.2246, -0.4629,  0.1270],\n",
       "         [-1.0078, -0.9375,  0.7539,  ..., -0.6562, -0.7617,  0.0449],\n",
       "         [-1.1719, -0.7969,  0.4922,  ..., -0.0283, -0.0791,  0.7148]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16), tensor([[[ 4.2188, -0.2041, -1.8438,  ..., -2.8594,  1.3594,  0.2891],\n",
       "         [-1.4141, -0.7109, -0.5469,  ..., -0.8203, -1.8672,  1.6484],\n",
       "         [-1.7812, -3.1406,  3.7344,  ..., -1.9062, -1.3750,  2.5312],\n",
       "         [-3.7969, -3.3438,  4.9062,  ...,  1.0312,  1.1406,  3.1406]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)), attentions=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.model(ids, output_hidden_states=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4096])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPSpeculatorPreTrainedModel(\n",
       "  (speculator): MLPSpeculator(\n",
       "    (emb): ModuleList(\n",
       "      (0-3): 4 x Embedding(128256, 3072)\n",
       "    )\n",
       "    (proj): ModuleList(\n",
       "      (0): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "      (1-3): 3 x Linear(in_features=3072, out_features=3072, bias=False)\n",
       "    )\n",
       "    (head): ModuleList(\n",
       "      (0-3): 4 x Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "    (ln): ModuleList(\n",
       "      (0-3): 4 x LayerNormParameterized()\n",
       "    )\n",
       "    (activation): GELU(approximate='none')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speculator = model.mlp_model.speculator\n",
    "len(speculator.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3072])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = speculator.emb[0](ids)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3072])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = speculator.proj[0](out.last_hidden_state)\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.047642905814858"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = speculator.emb_weight / speculator.state_weight\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3072])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "state = torch.add(state, z, alpha=alpha)\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 3072])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = speculator.activation(speculator.ln[0](state))\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128256])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = speculator.head[0](state)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128256, 3072])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speculator.head[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128256, 4096])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = model(ids, output_hidden_states=True)\n",
    "out2.logits.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
