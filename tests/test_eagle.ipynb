{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ['https_proxy'] = 'http://172.17.0.1:1081'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/work/axolotl/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Instantiating LlamaAttention without passing a `layer_idx` is not recommended and will lead to errors during the forward call if caching is used. Please make sure to provide a `layer_idx` when creating this class.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EaModel(\n",
       "  (base_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(128256, 4096)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (rotary_emb): LlamaRotaryEmbedding()\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "            (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "  )\n",
       "  (ea_layer): Model(\n",
       "    (embed_tokens): Embedding(128256, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0): LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "    (act): SiLU()\n",
       "    (logsoftmax): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from axolotl.models.eagle import EaModel\n",
    "\n",
    "\n",
    "model = EaModel.from_pretrained(base_model_path='/models/Meta-Llama-3-8B-Instruct', ea_model_path='yuhuili/EAGLE-LLaMA3-Instruct-8B')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embed_tokens): Embedding(128256, 4096, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0): LlamaDecoderLayer(\n",
       "      (self_attn): LlamaAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): LlamaMLP(\n",
       "        (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (act_fn): SiLU()\n",
       "      )\n",
       "      (post_attention_layernorm): LlamaRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=8192, out_features=4096, bias=False)\n",
       "  (act): SiLU()\n",
       "  (logsoftmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ea_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 381]),\n",
       " tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    264,  12514,\n",
       "           15592,  18328,  10968,    389,   8405,  13687,     11,  49150,     11,\n",
       "             323,  33445,  11503,     13,   4718,   9131,    374,    311,   1520,\n",
       "            3932,    304,    264,   6220,    323,  54584,   1648,     13,  24119,\n",
       "            6106,    701,  14847,    527,   1949,    505,  28856,     11,  89735,\n",
       "              11,  68763,     11,    477,  12079,   2262,     11,    323,  37106,\n",
       "             311,  10519,    264,   6928,    323,  74315,  13356,    627,   4599,\n",
       "           17011,    449,  25420,    477,    304,   1030,  38638,   4860,     11,\n",
       "            1935,    279,   6776,    311,  38263,    279,   4360,   4619,    315,\n",
       "           10209,  15465,   2038,     13,   1442,    499,    527,  44003,    922,\n",
       "             459,   4320,     11,  25670,    701,   9669,    323,   5766,  34000,\n",
       "           65383,    905,   2038,     13,   4718,   5915,    374,    311,  31087,\n",
       "             264,  11190,    323,  39319,  21976,     13, 128009, 128006,    882,\n",
       "          128007,    271, 108686,  61786,  32335, 110085, 123092, 111766,  21043,\n",
       "          112471, 128009, 128006,  78191, 128007,    271, 108686,  61786,  10110,\n",
       "              43,    290,    301,  71105,   7705, 107226,  25129, 102700,  13372,\n",
       "            9554, 117366, 114253,  43323, 102981,   9554, 111766, 116192, 108399,\n",
       "          119796, 117366,  98220,   9554,  53283,  13372,  17792, 101559,   1811,\n",
       "          108855,  37046,  81543,  35056, 102769,   9554,  28469, 102378,  88852,\n",
       "          107226,  98184,  43511,  58318, 117366,  98220,   9554, 111766,  49543,\n",
       "              16,     13,   3146, 101545,  70349, 101011, 112616, 101630, 110041,\n",
       "           14260, 104189, 106625, 100179,  43240,    334,  10110,     34,   2889,\n",
       "           13389,  65515, 123407, 108686,  61786,   9554,  33764,  46034,  34208,\n",
       "           42016,  23039, 104587,  21043, 126585,  81180,    226, 109895, 106444,\n",
       "           83266,   9554,  83266,  46961,   9174,     17,     13,   3146,  51385,\n",
       "           68464, 103420, 105665,  14260,  21601,  61786, 101630,    334,  10110,\n",
       "           17555,  82513,  85341, 123407, 103478, 102831, 120998, 106444,  83266,\n",
       "            9554,  83266,  98915,  34208, 111766,   9174,     18,     13,   3146,\n",
       "           51385, 118287, 100179,  14260, 108620, 102283,  70349, 101630,    334,\n",
       "           10110,  44801,    983,    301,   7923,  83305, 123407, 103478, 102831,\n",
       "          120998, 106444,  83266,   9554,  83266,  98915,  34208, 103693, 119372,\n",
       "          110952,   9080, 108870, 112948,  83266,   9554,  83266,  98915,   9174,\n",
       "              19,     13,   3146, 102283,  70626, 101011,  14260, 104189, 121478,\n",
       "             334,  10110,  48741,    437,  12093,   7453, 123407, 103478, 102831,\n",
       "          120998, 106444,  83266,   9554,  83266,  98915,  34208, 112948, 127833,\n",
       "          117540,  50182,  83266,   9554,  83266,  98915,   9174,     20,     13,\n",
       "            3146, 113536, 108481,  75146, 100179,  14260,  21601,  57106, 101630,\n",
       "          100179,    334,  10110,     36,   3059,    447,  13327,  12471,    352,\n",
       "          123407, 103478, 102831, 120998, 106444,  83266,   9554,  83266,  98915,\n",
       "           34208, 108481, 104083,  60632, 101630,  83266,   9554,  83266,  98915,\n",
       "            3490, 108787,  17792, 108619, 117366,  98220,   9554,  53283,  13372,\n",
       "          113679, 104587,  21043, 108686,  61786,   9554, 111766,  34208,  83266,\n",
       "           98915,   1811, 128009]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = model.get_tokenizer()\n",
    "\n",
    "prompt = '''<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a dedicated AI assistant focused on providing accurate, respectful, and supportive answers. Your mission is to help users in a safe and constructive way. Always ensure your responses are free from harmful, unethical, discriminatory, or illegal content, and strive to maintain a positive and unbiased perspective.\n",
    "When faced with unclear or incoherent questions, take the opportunity to clarify the issue instead of offering incorrect information. If you are unsure about an answer, acknowledge your limitations and avoid disseminating false information. Your goal is to foster a helpful and informative dialogue.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "梅西最好的几个朋友是谁<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "梅西（Lionel Messi）是一位著名的足球运动员，他的朋友圈包括许多足球界的知名人士。虽然我没有确切的信息，但以下是一些他与足球界的朋友：\n",
    "\n",
    "1. **克里斯蒂亚诺·罗纳尔多**（Cristiano Ronaldo）：梅西的对手和同行，也是葡萄牙国家队的队长。\n",
    "2. **安东尼奥·加西亚**（Antonio García）：阿根廷国家队的队友和朋友。\n",
    "3. **安赫尔·迪马里亚**（Ángel Di María）：阿根廷国家队的队友和巴黎圣日耳曼队的队友。\n",
    "4. **马科斯·罗霍**（Marcos Rojo）：阿根廷国家队的队友和曼彻斯特联队的队友。\n",
    "5. **埃塞基尔·加比亚尔**（Ezequiel Garay）：阿根廷国家队的队友和塞维利亚队的队友。\n",
    "\n",
    "这些人都是足球界的知名人物，也是梅西的朋友和队友。<|eot_id|>'''\n",
    "\n",
    "tokens = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "tokens.shape, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 381, 4096])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = model.base_model.model(tokens).last_hidden_state\n",
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 380, 4096])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state = hidden_state[:, :-1] #.roll(shifts=1, dims=1)\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 380, 4096])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hs = model.ea_layer(last_hidden_state, input_ids=tokens[:, 1:])\n",
    "out_hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 380, 128256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model.base_model.lm_head(out_hs)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   220,    258,    198,    220,     11,    264,  52067,     11,  18328,\n",
       "             11,     11,   6968,  35649,   2038,   1664,     11,    323,   9959,\n",
       "          10105,    311, 128009,  13291,    374,    311,   3493,   3932,  11322,\n",
       "            872,     11,     11,  49150,  11827,     11, 128009,    387,    430,\n",
       "          14847,    374,  49150,    323,  15837,    323,  15837,     11,    477,\n",
       "             11,    477,    904,  12659,    382,    323,  12192,    311,  10519,\n",
       "           6928,  49150,  16630,  49150,  16630,    382, 128009,    358,    264,\n",
       "            264,    477,  55861,  55861,  19684,   7540,     11,    358,   8475,\n",
       "           5995,    311,  38263,    323,   1217,    323,    315,   5042,  15465,\n",
       "          11503,    477, 128009,   1070,    527,  44003,    315,    279,   4320,\n",
       "            477,   6056,    701,  27924,    323,   3493,    279,  65383,   2038,\n",
       "           2038,    382, 128009,   5915,    374,    311,   3493,   7095,  49150,\n",
       "             11,  49150,   4676,    430, 128009, 128009,  18328,  78191,    323,\n",
       "             40,     11,    320,   3922,  10110,  79059,   9554,  11571,  11571,\n",
       "         128006,    271,  11571, 128007,   2675,  31809,  61786,  85523,    290,\n",
       "          71105,  71105,      8,  21043,  19483,  13372,  34208,   9554, 117366,\n",
       "           6447,  79059,   3922,  19361,  43240,  34208,  21043,  43240,   9554,\n",
       "          34208,  34208,  34208,  34208,  34208,  34208,   1811,  88852,  21043,\n",
       "          81543,  93233,   9554,   9554,  28469, 102378,  43511,  21043,  98184,\n",
       "          98184,  34208,  53283,   9554,  34208,  53283,  34208,     16,     13,\n",
       "         104829,     55,   5232,  34208,  34208,   9554,   5232,   5232, 104189,\n",
       "         104189,  10110,   5232,  10110,  10110, 100215,   2889,  13389, 100215,\n",
       "           7705,  21043,  34208,  34208,  34208,  34208,  34208,  42016,  34208,\n",
       "          23039,  21043, 104563,  34208,  34208,   9554,   9554,   9554,   9554,\n",
       "          34208,  34208,  46961,     17,     13,   3146,  12774,   5232,   5232,\n",
       "           5232,    334,  34208,   5232,   5232,  96618,  10110, 103478,  42825,\n",
       "          96618, 123407,  21043,  21043,   5232,  21043,   9554,  34208,  83266,\n",
       "          83266,  34208, 104563,   9174,     18,     13,   3146,  12774,  34208,\n",
       "          34208,    334,  10110,  34208,  34208,  70349,  96618,  10110,  51385,\n",
       "             75,    301,    409,  11644,    323,  10110,  34208,   9554,  34208,\n",
       "          34208,  34208,  83266,  83266,  34208,  25580,   9174,   9174,  70349,\n",
       "          34208,   9554,   9174,   9554,  83266,  83266,   9174,     19,     13,\n",
       "           3146,  34208,  35083,  11881,  34208,  34208,  34208,  34208,   5232,\n",
       "         102283,   3244, 123407,   2483,    323,  10110, 103478,   9554,   9554,\n",
       "          34208,   9554,  83266,  83266,   9174, 103478,   9174, 102769,   9174,\n",
       "           9174,  83266,  83266,  83266,   9174,     20,     13,   3146,  17039,\n",
       "         100179, 101011,    334,    334,  10110,  34208,  43511,   5232,    334,\n",
       "          10110, 103478,   1030,    447,  13327,    480, 114145,  42825,  10110,\n",
       "         103478, 120998,  34208, 106444,   9554,  83266,  98915,  34208,  25580,\n",
       "           3490,   3490, 101630,   9554,   9554,  83266,  83266,   3490, 108787,\n",
       "          21043,  80578,  16325,   9554,  34208,  53283,  34208,  34208,  34208,\n",
       "          21043,  34208,  61786,   9554, 111766,  34208,  42016,  83266,   3490,\n",
       "         128009, 128006]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ids = logits.argmax(dim=-1)\n",
    "out_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in\n",
      ", a chatting, assistant,, creating personalized information well, and relevant solutions to<|eot_id|> assistance is to provide users achieve their,, respectful manner,<|eot_id|> be that responses is respectful and bias and bias, or, or any practices.\n",
      "\n",
      " and promote to maintain positive respectful tone respectful tone.\n",
      "\n",
      "<|eot_id|> I a a or ambiguous ambiguousquate requests, I appropriate necessary to clarify and user and of simply incorrect answers or<|eot_id|> there are unsure of the answer or seek your uncertainty and provide theminating information information.\n",
      "\n",
      "<|eot_id|> goal is to provide trust respectful, respectful environment that<|eot_id|><|eot_id|> assistantassistant andI, (，（球的？？<|start_header_id|>\n",
      "\n",
      "？<|end_header_id|>You小西Mession Messi Messi)是个名和的足球！球，有多和是多的和和和和和和。以下是没有找的的信息，但他是些些和知的和知和1.李X：和和的：：罗罗（：（（ Cristianoristiano Cristiano）是和和和和和同和行是他们和和的的的的和和长2. **�：：：**和：：**:（阿ío**:）：是是：是的和队队和他们。\n",
      "3. **�和和**（和和里**:（安lel deán and（和的和和和队队和前。\n",
      "。\n",
      "里和的。\n",
      "的队队。\n",
      "4. **和格�和和和和：马ón）：í and（阿的的和的队队。\n",
      "阿。\n",
      "切。\n",
      "。\n",
      "队队队。\n",
      "5. **新尔斯****（和他：**（阿coquiel Giddiío（阿廷和国家的队友和前。\n",
      "\n",
      "。\n",
      "\n",
      "亚的的队队。\n",
      "\n",
      "这些是们中的和知和和和是和西的朋友和同队。\n",
      "\n",
      "<|eot_id|><|start_header_id|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(101)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept = out_ids[0, :-1] == tokens[0, 2:]\n",
    "accept.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
